<html>

<head>
<title>SEARCH BY MOBILE IMAGE BASED ON VISUAL AND SPATIAL CONSISTENCY</title>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta content="SEARCH BY MOBILE IMAGE BASED ON VISUAL AND SPATIAL CONSISTENCY"
name="description">
<meta
content="mobile image, feature group, spatial information, soft match"
name="keywords">
<meta content="Microsoft FrontPage 5.0" name="GENERATOR">
</head>

<body>

<h2 align="center"><font face="Times New Roman">SEARCH BY MOBILE IMAGE BASED ON VISUAL AND SPATIAL CONSISTENCY</font></h2>

<p><font face="Times New Roman"><br>
Xianglong Liu, Yihua Lou, Wei Yu, Bo Lang. Search by Mobile Image Based on Visual and Spatial Consistency.<b>&nbsp;</b><em>ICME</em>,
2011. [<a href="./icme2011_cr.pdf"><font color="#FF0000"><B>pdf</B></font></a> <a href="./icme2011_slides.pdf"><font color="#FF0000"><B>slides</B></font></a>]</font> 
<font face="Times New Roman"><br>
Xianglong Liu, Bo Lang, Yi Xu, Bo Cheng. Feature Grouping and Local Soft Match for Mobile Visual Search. <b>&nbsp;</b><em>Pattern Recognition Letters (accepted)</em>, 2011. [<a href="./prl201202.pdf"><font color="#FF0000"><B>pdf</B></font></a>]</font>

<ul>
  <li><font face="Times New Roman">Dataset&nbsp;
  <a href="http://sites.nlsde.buaa.edu.cn/~xlliu/mvs_images.zip">Mobile Visual Search Dataset</a> 
  (602M)</font></li>
</ul>

<blockquote>
  <p align="justify"><strong><font face="Times New Roman">Abstract:</font></strong><font face="Times New Roman"> 
  Performance of state-of-the-art image retrieval systems has been improved significantly using bag-of-words approaches. After represented by visual words quantized from local features, images can be indexed and retrieved using scalable textual retrieval approaches. However, there exist at least two issues unsolved, especially for search by mobile images with large variations: (1) the loss of features discriminative power due to quantization; and (2) the underuse of spatial relationships among visual words. To address both issues, considering properties of mobile images, this paper presents a novel method coupling visual and spatial information consistently: to improve discriminative power, features of the query image are first grouped using both matched visual features and their spatial relationships; Then grouped features are softly matched to alleviate quantization loss. Experiments on both UKBench database and a collected database with more than one million images show that the proposed method achieves 10% improvement over the approach with a vocabulary tree and bundled feature method. <br>
  <strong>Keywords: </strong><b>mobile image, feature group, spatial information, soft match.</b></font></p>
 

<p><font face="Times New Roman"><a href="http://sites.nlsde.buaa.edu.cn/~xlliu/">Back to Xianglong Liu's homepage</a>.</font></p>
</body>
</html>